---
# This section is used to set the title and description of the lesson on Newline. Do not edit `token`.
# Changes you make here will overwrite the existing content on Newline when synced via Github.
# Begin the body of the lesson below the final `---`.

token: eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJjb250ZW50X2lkIjoyMjE5MywiY29udGVudF90eXBlIjoiTGVzc29uIn0.PgoY1Amah-hfZulM1ZhitbT52qfH2MhC2EyflV_OPmk

title: >-
  Fundamentals of Usability Testing
description: >-
  Overview of how to design, conduct, and report a usability test
---
# What is a usability test? 
Usability testing is a way to see how easy to use something is by testing it with real users. Users are asked to complete tasks, typically while they are being observed by a researcher, to see where they encounter problems and experience confusion.

![user test](http://image.slidesharecdn.com/leanusertestingintroga-130913123202-phpapp02/95/lean-user-testing-intro-16-638.jpg?cb=1379075746)

# Types of Usability Tests
- Problem Discovery: A problem discovery usability test is the most common type of usability study. The goal is to uncover (and fix) as many usability problems as possible. When you have a handful of participants attempt a few realistic tasks you can uncover the most common issues. 

- Benchmark or Summative Study: Problems were found and new designs were created. But did those design changes actually make the interface easier to use? The goal of a benchmark study is to answer the question: How usable is the interface? Measuring the usability of an interface before design changes are made allows you to set a benchmark to compare future designs against. 

- Competitive Study: Collecting benchmark data tells you how usable your website is and how users are performing on key tasks. A stand-alone benchmark generates a lot of data, but without a comparison to an earlier benchmark you're often left wondering "are these results good or bad?" To provide a meaningful comparison, have another set of participants attempt the same set of tasks on competing websites or products. 

- Eye Tracking: Where people look and where they click are similar, but not always the same. When you need to understand both where participants eyes are drawn in designs and the sequences of gaze paths, an eye-tracking study is the way to go. The current technology only supports in-person testing. 

- Learnability Study: Most usability studies assess first time use. Even when using participants who have experience with an interface, the task details are almost always unfamiliar in some way. Consequently, the findings often describe initial use, rather than usage over time. By having participants attempt the same tasks repeatedly in a study, you can quantify the learning curve.

# Usability Test Methods
Testing modes or methods are the ways to conduct a usability study on any interface type. There are three main testing methods; each has its strengths and weaknesses:

- Moderated in-person: A facilitator is co-located with the participant (often in a lab).

- Moderated remote: The participant and facilitator are in different locations. Screen sharing software is used and the facilitator can watch the participant attempt tasks and ask for details on problems.

- Unmoderated remote: Software administers tasks automatically to participants around the world. You can collect a lot of data quickly and for a fraction of the cost of in-person testing. In many cases you have a recording of the participant's screen and webcam, but there's no way to simultaneously interact with all participants.

http://www.measuringu.com/blog/five-types-usability.php

# How to conduct a usability test? 
### 1. Design Your Study
- Obviously you cannot analyze your entire presentation, nor can you study all the actions that all types of users might perform.
- Decide on a category of users, define some tasks that they would do frequently, and choose four to five benchmark tasks to evaluate.
- Carefully select these tasks to simulate what actual users of the site would do.
- Once you have your tasks, design the experiment

### 2. Finalize Testing Instruments 
A good usability study should include the following: 
- Script
- Informed consent
- Pre-experiment questionnaire
- Free observation checklist
- Tasks
- Post experiment questionnaire
- Post experiment interview questions

http://www.ojr.org/ojrs-five-guide-to-do-it-yourself-website-usability-testing/

### 3. Conduct the Test
- Carefully observe (and record if they consent) each session and take notes about the participants' interactions with the site. 
- You must recruit at least two  participants each. Try to keep them in the same target demographic as your personas. 
- Make sure that your test is designed to be broken up into different sections and give each of those sections an allotted time. 
- Obviously, you should interact with the site yourself ahead of time to become familiar with its functionality, including functionality outside of what your task includes (users may get off course, lost, distracted, etc., and you'll need to be prepared to help them recover). 

### 4. Data Analysis
- Inspect your data and determine if/how they address your hypotheses.
- Look at descriptive statistics (to describe, show or summarize data in a meaningful way so patterns might emerge) primarily.
- If you are able to, you should also look at appropriate inferential statistics (to infer from the sample data what the population might think). 

### 5. Present Results
- When reporting results from a usability test, you should focus primarily on your findings and recommendations that are differentiated by levels of severity. Keep the sections short, use tables to display the metrics, and use visual examples to demonstrate problem areas, when possible. 

- As you are reviewing the data, consider how global the problem is throughout the site and how severe (or serious) the problem is.  Your findings may have implications for other pages in the site (global). 

   * Critical:  If we do not fix this, users will not be able to complete the scenario.
   * Serious:  Many users will be frustrated if we do not fix this; they may give up.
   * Minor:  Users are annoyed, but this does not keep them from completing the scenario. This should be revisited later.


# Resources
- [Planning a Usability Test](https://www.usability.gov/how-to-and-tools/methods/planning-usability-testing.html)
- [What goes into a Usability Test Script](https://boagworld.com/usability/what-goes-into-a-user-testing-script/)
- [Reporting Usability Test Results](https://www.usability.gov/how-to-and-tools/methods/reporting-usability-test-results.html) 
- [Lexi's Usability Test Resources](https://www.dropbox.com/sh/cmqhv0m9f3bz4hj/AACNMJYC80p9i2mcdaR23sNda?dl=0)


